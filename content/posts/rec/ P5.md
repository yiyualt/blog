---
title: "Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5)"
date: 2022-04-10T01:22:46+09:00
draft: true
---
## Questions: Can we solve recommendation tasks as NLP tasks? This paper [1] gives you the answer.

This work proposes a unified model, P5, that takes in multiple types of data as input and then output for different tasks, including sequential recommendation, rating prediction, explanation generation. The model adopts an standard Encoder-Decoder framework and then is trained on TRAIN. After training, the prompt learning (i.e., sort of like mask language modeling task) is applied to tune the model. Aftering updating the parameters of the model, P5 can perform multi-task recommendations and achieve some of the state-of-the-art performance. 

### Main results
![your image](/images/40.png)

[1] Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5). Shijie Geng et al. ArXiv'22. 